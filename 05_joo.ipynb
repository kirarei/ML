{
 "metadata": {
  "name": "",
  "signature": "sha256:611a6b399675567d9e49f46e2bd6abc4f435e2ca16a87f26e66f740beccf14bb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadSampleSet():\n",
      "    dataMat = []; # dataMat \ub97c list \ud654\n",
      "    fr = open('SampleSet.txt')\n",
      "    for line in fr.readlines():     #line\uc774\ub77c\ub294 \ubcc0\uc218\uc5d0 \ub77c\uc778\ub05d\uae4c\uc9c0 \ubc18\ubcf5   \n",
      "        lineArr = line.strip().split()      # \ub744\uc5b4\uc4f0\uae30, split() : \\t, \\_(\uc2a4\ud398\uc774\uc2a4),white space \n",
      "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
      "    return dataMat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadSampleSet():\n",
      "    dataMat = [];\n",
      "    fr = open('SampleSet.txt')\n",
      "    for line in fr.readlines():        \n",
      "        lineArr = line.strip().split()      # \ub744\uc5b4\uc4f0\uae30, split() : \\t, \\_(\uc2a4\ud398\uc774\uc2a4),white space \n",
      "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
      "    return dataMat\n",
      "\n",
      "def plotSampleData(dataSample):\n",
      "    import matplotlib.pyplot as plt\n",
      "    dataArr = array(dataSample)\n",
      "    n = shape(dataArr)[0]\n",
      "    xcord1 = []; ycord1 = [] # \uccab \ubc88\uc9f8 \uadf8\ub8f9\uc744 \ud45c\ud604\ud560 list\ub97c \uc0dd\uc131\n",
      "    for i in range(n): # \uc804\uccb4 \uc5f4 \ub9cc\ud07c loop\ub97c \uc2e4\ud589\n",
      "        xcord1.append(dataArr[i,0]); ycord1.append(dataArr[i,1])\n",
      "    fig = plt.figure() # \uadf8\ub9bc\uc744 \uadf8\ub9b4 \uacf5\uac04\uc744 \ub9cc\ub4ec\n",
      "    ax = fig.add_subplot(111) # 1X1 \uacf5\uac04\uc758 1\ubc88 \uacf5\uac04\uc5d0 ax \uadf8\ub798\ud504\ub97c \ub9cc\ub4ec\n",
      "    \n",
      "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='x')\n",
      "    plt.xlabel('X'); plt.ylabel('Y');\n",
      "    plt.show()\n",
      "\n",
      "def classfy(data, weights, refValue):    \n",
      "    value = sum(data * weights.transpose())\n",
      "    if value > refValue: return 1.0 # \ud589\uc740 0 , \uc5f4\uc740 1\n",
      "    else: return 0.0\n",
      "    \n",
      "def plotClassfy(dataSample):\n",
      "    import matplotlib.pyplot as plt # \uadf8\ub798\ud504\ub97c \uadf8\ub9b4 \ubaa8\ub4c8\uc744 import\n",
      "    dataArr = array(dataSample) # dataMat\uc740 list \ud0c0\uc785\uc774\ubbc0\ub85c numpy\uc758 Array \ud0c0\uc785\uc73c\ub85c \ubcc0\uacbd\n",
      "    weights = [2.0, 1.0]\n",
      "    n = shape(dataArr)[0] # dataArr\uc758 \ud615\ud0dc\ub97c \ub098\ud0c0\ub0b4\ub294 \uccab\ubc88\uc9f8 \uc694\uc18c(\uc5f4\uc758 \uac2f\uc218)\ub97c \uac00\uc838\uc634\n",
      "    xcord1 = []; ycord1 = [] # \uccab \ubc88\uc9f8 \uadf8\ub8f9\uc744 \ud45c\ud604\ud560 list\ub97c \uc0dd\uc131\n",
      "    xcord2 = []; ycord2 = [] # \ub450 \ubc88\uc9f8 \uadf8\ub8f9\uc744 \ud45c\ud604\ud560 list\ub97c \uc0dd\uc131\n",
      "    for i in range(n): # \uc804\uccb4 \uc5f4 \ub9cc\ud07c loop\ub97c \uc2e4\ud589\n",
      "        if int(classfy(dataArr[i], array(weights), 30))== 1: # 1\ubc88 \uadf8\ub8f9\uc774\uba74\n",
      "            xcord1.append(dataArr[i,0]); ycord1.append(dataArr[i,1])\n",
      "        else: # 1\ubc88 \uadf8\ub8f9\uc774 \uc544\ub2c8\uba74\n",
      "            xcord2.append(dataArr[i,0]); ycord2.append(dataArr[i,1])\n",
      "    fig = plt.figure() # \uadf8\ub9bc\uc744 \uadf8\ub9b4 \uacf5\uac04\uc744 \ub9cc\ub4ec\n",
      "    ax = fig.add_subplot(111) # 1X1 \uacf5\uac04\uc758 1\ubc88 \uacf5\uac04\uc5d0 ax \uadf8\ub798\ud504\ub97c \ub9cc\ub4ec\n",
      "    \n",
      "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
      "    ax.scatter(xcord2, ycord2, s=30, c='green', marker='v')\n",
      "    x = arange(0, 20.0, 1.0) # 0\uc5d0\uc11c\ubd80\ud130 20\uac1c\uc758 \uc22b\uc790\ub97c 1\uc758 \uac04\uaca9\uc73c\ub85c \uadf8\ub9b4 \uac83\n",
      "    y = -2*x + 30\n",
      "    ax.plot(x, y)\n",
      "    plt.xlabel('X'); plt.ylabel('Y');\n",
      "    plt.show()\n",
      "    \n",
      "dataSample = loadSampleSet()\n",
      "print dataSample\n",
      "plotSampleData(dataSample)\n",
      "print plotSampleData(dataSample)\n",
      "plotClassfy(dataSample)\n",
      "print plotClassfy((dataSample))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0.0, 0.0], [0.0, 5.0], [0.0, 10.0], [0.0, 15.0], [0.0, 20.0], [5.0, 0.0], [5.0, 5.0], [5.0, 10.0], [5.0, 15.0], [5.0, 20.0], [10.0, 0.0], [10.0, 5.0], [10.0, 10.0], [10.0, 15.0], [10.0, 20.0], [15.0, 0.0], [15.0, 5.0], [15.0, 10.0], [15.0, 15.0], [15.0, 20.0], [20.0, 0.0], [20.0, 5.0], [20.0, 10.0], [20.0, 15.0], [20.0, 20.0]]\n",
        "None"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "None"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sigmaoid\ub97c \uacc4\uc0b0\ud558\ub294 \ud568\uc218\n",
      "def sigmoid(inX):\n",
      "    return 1.0/(1+exp(-inX))\n",
      "\n",
      "def plotSigmoid(inX):\n",
      "    import matplotlib.pyplot as plt # \uadf8\ub798\ud504\ub97c \uadf8\ub9b4 \ubaa8\ub4c8\uc744 import\n",
      "    fig = plt.figure() # \uadf8\ub9bc\uc744 \uadf8\ub9b4 \uacf5\uac04\uc744 \ub9cc\ub4ec\n",
      "    ax = fig.add_subplot(111) # 1X1 \uacf5\uac04\uc758 1\ubc88 \uacf5\uac04\uc5d0 ax \uadf8\ub798\ud504\ub97c \ub9cc\ub4ec\n",
      "    x = arange(-inX, inX, 0.005)\n",
      "    y = sigmoid(x)\n",
      "    ax.plot(x, y)\n",
      "    plt.xlabel('X'); plt.ylabel('Sigmoid(X)');\n",
      "    plt.show()\n",
      "    \n",
      "plotSigmoid(5)\n",
      "plotSigmoid(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\uc2dc\uadf8\ubaa8\uc774\ub4dc \ud568\uc218\ub97c \uc4f0\ub294 \uc774\uc720\n",
      "2a+b <= 30 \uc774\uba74 0\n",
      "2a+b > 30  \uc774\uba74 1\n",
      "\n",
      "\n",
      "2a+b <= 0.5 \uc774\uba74 0\n",
      "\ub85c\uadf8\uac12\uc744 \ub9cc\ub4e4\uc5b4\uc11c \ud655\ub960\ub85c \ub9cc\ub4e4\uc5b4\uc11c \uc0ac\uc6a9 \uac00\ub2a5\n",
      "\ub204\uc801\uc2dc\ud0a4\uba74 \ud655\ub960\ubc00\ub3c4\ud568\uc218\uac00 \ub428\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def f_prime_minimum(x):\n",
      "    return 4 * x**3 - 9 * x**2\n",
      "\n",
      "def f_function_minimum(x):\n",
      "    return x**4 - 3 * x**3 + 2\n",
      "\n",
      "def f_minimum(inX, gamma, precision):\n",
      "    x_old = 0\n",
      "    x_new = inX\n",
      "    while abs(x_new - x_old) > precision:\n",
      "        x_old = x_new\n",
      "        x_new = x_old - gamma * f_prime_minimum(x_old)\n",
      "    return x_new\n",
      "\n",
      "def plotMinimum(startX):\n",
      "    import matplotlib.pyplot as plt # \uadf8\ub798\ud504\ub97c \uadf8\ub9b4 \ubaa8\ub4c8\uc744 import\n",
      "    fig = plt.figure() # \uadf8\ub9bc\uc744 \uadf8\ub9b4 \uacf5\uac04\uc744 \ub9cc\ub4ec\n",
      "    ax = fig.add_subplot(111) # 1X1 \uacf5\uac04\uc758 1\ubc88 \uacf5\uac04\uc5d0 ax \uadf8\ub798\ud504\ub97c \ub9cc\ub4ec\n",
      "    x = arange(-1, 3, 0.005)\n",
      "    y = f_function_minimum(x)\n",
      "    ax.plot(x, y)\n",
      "    minimumX = f_minimum(startX, 0.01, 0.00001)\n",
      "    minimumY = f_function_minimum(minimumX)\n",
      "    gradX = f_prime_minimum(minimumX)\n",
      "    x1 = arange(minimumX - 1.0, minimumX + 1.0, 0.1)\n",
      "    y1 = gradX*x1 + minimumY\n",
      "    ax.plot(x1, y1)\n",
      "    plt.xlabel('X'); plt.ylabel('Y');\n",
      "    plt.show()\n",
      " \n",
      "plotMinimum(6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def f_prime_maximum(x):\n",
      "    return (-10)*(2*x**3 + 3 * x**2 - x - 1)\n",
      "\n",
      "def f_function_maximum(x):\n",
      "    return (x + 2)*(x + 1)*x*(x - 1)*(-5)\n",
      "\n",
      "def f_maximum(inX, gamma, precision):\n",
      "    x_old = 0\n",
      "    x_new = inX\n",
      "    while abs(x_new - x_old) > precision:\n",
      "        x_old = x_new\n",
      "        x_new = x_old + gamma * f_prime_maximum(x_old)\n",
      "    return x_new\n",
      "\n",
      "def plotMaximum(startX):\n",
      "    import matplotlib.pyplot as plt # \uadf8\ub798\ud504\ub97c \uadf8\ub9b4 \ubaa8\ub4c8\uc744 import\n",
      "    fig = plt.figure() # \uadf8\ub9bc\uc744 \uadf8\ub9b4 \uacf5\uac04\uc744 \ub9cc\ub4ec\n",
      "    ax = fig.add_subplot(111) # 1X1 \uacf5\uac04\uc758 1\ubc88 \uacf5\uac04\uc5d0 ax \uadf8\ub798\ud504\ub97c \ub9cc\ub4ec\n",
      "    x = arange(-2, 1, 0.005)\n",
      "    y = f_function_maximum(x)\n",
      "    ax.plot(x, y)\n",
      "    maximumX = f_maximum(startX, 0.01, 0.00001)\n",
      "    maximumY = f_function_maximum(maximumX)\n",
      "    gradX = f_prime_maximum(maximumX)\n",
      "    x1 = arange(maximumX - 1.0, maximumX + 1.0, 0.1)\n",
      "    y1 = gradX*x1 + maximumY\n",
      "    ax.plot(x1, y1)\n",
      "    plt.xlabel('X'); plt.ylabel('Y');\n",
      "    plt.show()\n",
      " \n",
      "plotMaximum(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print \"\uae30\uc6b8\uae30 \ud558\uac15\"\n",
      "plotMinimum(6)\n",
      "plotMinimum(0)\n",
      "print \"\uae30\uc6b8\uae30 \uc0c1\uc2b9\"\n",
      "plotMaximum(-1)\n",
      "plotMaximum(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\uae30\uc6b8\uae30 \ud558\uac15\n",
        "\uae30\uc6b8\uae30 \uc0c1\uc2b9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data\ub97c \ubd88\ub7ec\uc624\ub294 \ud568\uc218\n",
      "def loadDataSet():\n",
      "    dataMat = []; labelMat = []  # \ub9ac\uc2a4\ud2b8 type\uc73c\ub85c dataMat\uacfc labelMat \ubcc0\uc218\ub97c \uc0dd\uc131\n",
      "    fr = open('testSet.txt')\n",
      "    for line in fr.readlines():\n",
      "        # strip\ub294 \ubb38\uc790\uc5f4\uc758 \uc591 \ub05d \uacf5\ubc31\uc744 \uc5c6\uc560\ub294 \ud568\uc218\n",
      "        # split\ub294 \ubb38\uc790\uc5f4\uc744 \ucabc\uac1c\ub294 \ud568\uc218, \uc778\uc790\uac12\uc774 \uc5c6\uc73c\uba74 ' ' \uc744 \uae30\ubcf8\uc73c\ub85c \uc790\ub978\ub2e4.\n",
      "        lineArr = line.strip().split()\n",
      "        \n",
      "        # dataMat\uc5d0 3\uc5f4\uc9dc\ub9ac \ub370\uc774\ud130\ub97c \ucd94\uac00\ud55c\ub2e4.\n",
      "        # \uc138 \ubc88\uc9f8 \uc5f4\uc5d0 1.0\uc744 \ub123\uc740 \uc774\uc720\ub294 Regression \ud6c4 \uc808\ud3b8\uac12\uc744 \uacc4\uc0b0\ud558\uae30 \uc704\ud568\n",
      "        # ex) ax + by + c = 0 \uc774\ub77c \ud560 \ub54c, a\ub294 \uccab \ubc88\uc9f8 \uc5f4\ub85c \uacc4\uc0b0\ub418\uba70, b\ub294 \ub450 \ubc88\uc9f8 \uc5f4, c\ub294 \uc138 \ubc88\uc9f8 \uc5f4\uc774\ub2e4.\n",
      "        dataMat.append([float(lineArr[0]), float(lineArr[1]), 1.0])\n",
      "        labelMat.append(int(lineArr[2]))\n",
      "    return dataMat,labelMat\n",
      "\n",
      "# \uc0c1\uc2b9 Gradient\ub97c \uacc4\uc0b0\ud558\ub294 \ud568\uc218\n",
      "# dataMatIn [\uccab \ubc88\uc9f8 \uc694\uc18c, ..., n \ubc88\uc9f8 \uc694\uc18c, 1.0]\n",
      "# classLabel [\uccab \ubc88\uc9f8 \uadf8\ub8f9, ..., m \ubc88\uc9f8 \uadf8\ub8f9]\n",
      "# maxCycles \ub9e4\uac1c\ubcc0\uc218\ub97c \uad6c\ud558\uae30 \uc704\ud574\uc11c \uc2e4\ud589\ub418\ub294 \ubc18\ubcf5\ud69f\uc218\n",
      "def gradAscent(dataMatIn, classLabels, maxCycles):\n",
      "    dataMatrix = mat(dataMatIn)             #list \ud0c0\uc785\uc744 numpy\uc758 Matrix\ud0c0\uc785\uc73c\ub85c \ubc14\uafd4\uc90c\n",
      "    #print \"dataMatIn type :\", type(dataMatIn)\n",
      "    #print \"dataMatrix type :\", type(dataMatrix)\n",
      "    labelMat = mat(classLabels).transpose() #convert to NumPy matrix\n",
      "    m,n = shape(dataMatrix) # \ud589\uacfc \uc5f4\uc744 \uac00\uc838\uc628\ub2e4.\n",
      "    #print \"\ud589\uc758 \uac2f\uc218 :\", m\n",
      "    #print \"\uc5f4\uc758 \uac2f\uc218 :\", n\n",
      "    #print dataMatrix.transpose()\n",
      "    alpha = 0.001\n",
      "    #maxCycles = 3000\n",
      "    weights = ones((n,1))  # [\ud589\uc758 \uac2f\uc218 : Input\uc758 \uc5f4\uc758 \uac2f\uc218, \uc5f4\uc758 \uac2f\uc218 : 1] \ub9cc\ud07c 1\ub85c \ucd08\uae30\ud654\n",
      "    for k in range(maxCycles):              # heavy on matrix operations\n",
      "        # \uc5ec\uae30\uc11c \ud589\ub82c\uacf1\uc744 \uc774\uc6a9\ud558\uc5ec 1\uac1c\uc758 \uac12\ub9cc \uc804\ub2ec \ub428\n",
      "        # \ub0b4\uc801\uc758 \uac1c\ub150\ucc98\ub7fc \uacf1\ud558\uace0 \ub354\ud55c\ub2e4.\n",
      "        h = sigmoid(dataMatrix * weights)     # \uac01 \uc694\uc18c\uc5d0 weight \uac12\uc744 \uacf1\ud587\uc11c sigmoid \ud568\uc218\ub97c \ud638\ucd9c\ud55c\ub2e4.\n",
      "        error = (labelMat - h)                # sigmoid\ub97c \uc774\uc6a9\ud574\uc11c \uadf8\ub8f9\uc744 \ub098\ub208\ub2e4.\n",
      "        weights = weights + alpha * dataMatrix.transpose() * error # \uac01 \uc694\uc18c\uc758 weight \uac12\uc744 \uc870\uc808\ud574\uc900\ub2e4.\n",
      "    return weights;\n",
      "\n",
      "def gradDescent(dataMatIn, classLabels, maxCycles):\n",
      "    dataMatrix = mat(dataMatIn)             #list \ud0c0\uc785\uc744 numpy\uc758 Matrix\ud0c0\uc785\uc73c\ub85c \ubc14\uafd4\uc90c\n",
      "    #print \"dataMatIn type :\", type(dataMatIn)\n",
      "    #print \"dataMatrix type :\", type(dataMatrix)\n",
      "    labelMat = mat(classLabels).transpose() #convert to NumPy matrix \n",
      "    m,n = shape(dataMatrix) # shape :\ud589\uacfc \uc5f4\uc744 \uac00\uc838\uc628\ub2e4.\n",
      "    #print \"\ud589\uc758 \uac2f\uc218 :\", m\n",
      "    #print \"\uc5f4\uc758 \uac2f\uc218 :\", n\n",
      "    #print dataMatrix.transpose()\n",
      "    alpha = 0.001 # \uc801\uc808\ud558\uac8c \uc815\uc758 , local lower, higher\ub85c \ube60\uc9c0\uae30\uc27d\uae30\ub54c\ubb38\uc5d0\n",
      "    #maxCycles = 3000\n",
      "    weights = ones((n,1))  # [\ud589\uc758 \uac2f\uc218 : Input\uc758 \uc5f4\uc758 \uac2f\uc218, \uc5f4\uc758 \uac2f\uc218 : 1] \ub9cc\ud07c 1\ub85c \ucd08\uae30\ud654\n",
      "    for k in range(maxCycles):              # heavy on matrix operations \uc0c1\uc218\uc640 weight \uac12 \ucc3e\uae30\uc704\ud574(\ucd5c\uc801\ud654\ub41c slope\uc640 \uc0c1\uc218-\uc5d0\ub7ec\ub97c \ucd5c\uc18c\ud654 - for\ubb38 \ub9ce\uc774 \ub3cc\ub824\uc57c \ud568)\n",
      "        # \uc5ec\uae30\uc11c \ud589\ub82c\uacf1\uc744 \uc774\uc6a9\ud558\uc5ec 1\uac1c\uc758 \uac12\ub9cc \uc804\ub2ec \ub428\n",
      "        # \ub0b4\uc801\uc758 \uac1c\ub150\ucc98\ub7fc \uacf1\ud558\uace0 \ub354\ud55c\ub2e4.\n",
      "        h = sigmoid(dataMatrix * weights)     # \uac01 \uc694\uc18c\uc5d0 weight \uac12\uc744 \uacf1\ud587\uc11c sigmoid \ud568\uc218\ub97c \ud638\ucd9c\ud55c\ub2e4.\n",
      "        error = (labelMat - h)                # sigmoid\ub97c \uc774\uc6a9\ud574\uc11c \uadf8\ub8f9\uc744 \ub098\ub208\ub2e4.labelMat =\uce21\uc815\uce58(0.1), h :\uc608\uce21\uac12 (0~1)  -1<error <1\n",
      "        weights = weights - alpha * dataMatrix.transpose() * error # \uac01 \uc694\uc18c\uc758 weight \uac12\uc744 \uc870\uc808\ud574\uc900\ub2e4.\n",
      "    return weights;\n",
      "\n",
      "# \uadf8\ub798\ud504\ub97c \uadf8\ub824\uc8fc\ub294 \ud568\uc218 \n",
      "# weight type\uc740 numpy\uc758 Array \ud0c0\uc785\n",
      "def plotBestFit(weights):\n",
      "    #print \"Weights type :\", type(weights)\n",
      "    import matplotlib.pyplot as plt # \uadf8\ub798\ud504\ub97c \uadf8\ub9b4 \ubaa8\ub4c8\uc744 import\n",
      "    # \ucc38\uace0 \ub9c1\ud06c\n",
      "    # http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot\n",
      "    # http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter\n",
      "    # http://matplotlib.org/api/markers_api.html#matplotlib.markers.MarkerStyle\n",
      "    dataMat,labelMat = loadDataSet() # \ud45c\ud604\ud560 data\ub97c \ubd88\ub7ec \uc634\n",
      "    dataArr = array(dataMat) # dataMat\uc740 list \ud0c0\uc785\uc774\ubbc0\ub85c numpy\uc758 Array \ud0c0\uc785\uc73c\ub85c \ubcc0\uacbd\n",
      "    n = shape(dataArr)[0] # dataArr\uc758 \ud615\ud0dc\ub97c \ub098\ud0c0\ub0b4\ub294 \uccab\ubc88\uc9f8 \uc694\uc18c(\uc5f4\uc758 \uac2f\uc218)\ub97c \uac00\uc838\uc634\n",
      "    xcord1 = []; ycord1 = [] # \uccab \ubc88\uc9f8 \uadf8\ub8f9\uc744 \ud45c\ud604\ud560 list\ub97c \uc0dd\uc131\n",
      "    xcord2 = []; ycord2 = [] # \ub450 \ubc88\uc9f8 \uadf8\ub8f9\uc744 \ud45c\ud604\ud560 list\ub97c \uc0dd\uc131\n",
      "    for i in range(n): # \uc804\uccb4 \uc5f4 \ub9cc\ud07c loop\ub97c \uc2e4\ud589\n",
      "        if int(labelMat[i])== 1: # 1\ubc88 \uadf8\ub8f9\uc774\uba74\n",
      "            xcord1.append(dataArr[i,0]); ycord1.append(dataArr[i,1])\n",
      "        else: # 1\ubc88 \uadf8\ub8f9\uc774 \uc544\ub2c8\uba74\n",
      "            xcord2.append(dataArr[i,0]); ycord2.append(dataArr[i,1])\n",
      "    fig = plt.figure() # \uadf8\ub9bc\uc744 \uadf8\ub9b4 \uacf5\uac04\uc744 \ub9cc\ub4ec\n",
      "    ax = fig.add_subplot(111) # 1X1 \uacf5\uac04\uc758 1\ubc88 \uacf5\uac04\uc5d0 ax \uadf8\ub798\ud504\ub97c \ub9cc\ub4ec\n",
      "    \n",
      "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='x')\n",
      "    ax.scatter(xcord2, ycord2, s=30, c='green', marker='v')\n",
      "    x = arange(-3.0, 3.0, 0.1)\n",
      "    y = (-weights[2]-weights[0]*x)/weights[1]\n",
      "    ax.plot(x, y)\n",
      "    plt.xlabel('X1'); plt.ylabel('X2');\n",
      "    plt.show()\n",
      "    \n",
      "dataMat, labelMat = loadDataSet()\n",
      "weight = gradAscent(dataMat, labelMat, 1)\n",
      "plotBestFit(weight.getA())\n",
      "#weight = gradAscent(dataMat, labelMat, 5)\n",
      "#plotBestFit(weight.getA())\n",
      "#weight = gradAscent(dataMat, labelMat, 50)\n",
      "#plotBestFit(weight.getA())\n",
      "weight = gradAscent(dataMat, labelMat, 500)\n",
      "plotBestFit(weight.getA())\n",
      "\n",
      "weight = gradDescent(dataMat, labelMat, 1)\n",
      "plotBestFit(weight.getA())\n",
      "#weight = gradDescent(dataMat, labelMat, 5)\n",
      "#plotBestFit(weight.getA())\n",
      "#weight = gradDescent(dataMat, labelMat, 50)\n",
      "#plotBestFit(weight.getA())\n",
      "weight = gradDescent(dataMat, labelMat, 500)\n",
      "plotBestFit(weight.getA())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:3: RuntimeWarning: overflow encountered in exp\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import random\n",
      "alpha=0.001\n",
      "\n",
      "x=[1.47, 1.50, 1.52, 1.55, 1.57, 1.60, 1.63, 1.65, 1.68,\\\n",
      "   1.70, 1.73, 1.75, 1.78, 1.80, 1.83]\n",
      "y=[52.21, 53.12, 54.48, 55.84, 57.20, 58.57, 59.93, 61.29,\\\n",
      "   63.11, 64.47, 66.28, 68.10, 69.92, 72.19, 74.46]\n",
      "\n",
      "def computeAvgError(a,b,x,y):\n",
      "    totalError = 0\n",
      "    for i in range(0, len(x)):\n",
      "        totalError += (y[i] - (a * x[i] + b)) ** 2\n",
      "    return totalError / float(len(x))\n",
      "\n",
      "#x: attribute, 1d float array\n",
      "#y: class, 1d int array\n",
      "#alpha: learning rate\n",
      "\n",
      "def GradientDescent(x,y,alpha,iter):\n",
      "    a=random.random()\n",
      "    b=random.random()\n",
      "    n=len(x)\n",
      "    for j in range(iter):\n",
      "        aGradient = 0\n",
      "        bGradient = 0\n",
      "        for i in range(n):\n",
      "            aGradient += (2./n) * (y[i] - ((a * x[i]) + b))*(-x[i])\n",
      "            bGradient += (2./n) * (y[i] - ((a * x[i]) + b))\n",
      "        a = a - (alpha * aGradient)\n",
      "        b = b - (alpha * bGradient)\n",
      "        if(j%500==0):\n",
      "            print \"iter:{0} a={1} b={2} AvgError={3}\".format(j,a,b,computeAvgError(a,b,x,y))\n",
      "    return a, b\n",
      "\n",
      "#x,y=genData(100,1,1)\n",
      "a,b=GradientDescent(x,y,alpha,30000)\n",
      "yhat=[]\n",
      "for i in range(len(x)):\n",
      "    yhat.append(a*x[i]+b)\n",
      "    print \"i{0} x={1} y={2} yhat={3}\".format(i,x[i],y[i],yhat[i])\n",
      "error=computeAvgError(a,b,x,y)\n",
      "print \"y={0}x+{1}, error={2}\".format(a,b,error)\n",
      "\n",
      "plt.scatter(x,y)\n",
      "plt.plot(x,yhat)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "iter:0 a=1.11659697017 b=-0.0446325718979 AvgError=3678.19196962\n",
        "iter:500 a=48.5657569987 b=-28.5694950574 AvgError=112.330134097\n",
        "iter:1000 a=56.8211191214 b=-33.5158305175 AvgError=3.98464474264\n",
        "iter:1500 a=58.2444495344 b=-34.3519804994 AvgError=0.693856974984\n",
        "iter:2000 a=58.4767696412 b=-34.4714960361 AvgError=0.595114361632\n",
        "iter:2500 a=58.5013725563 b=-34.4659102066 AvgError=0.593377768716\n",
        "iter:3000 a=58.4896566246 b=-34.4383326336 AvgError=0.594606423956\n",
        "iter:3500 a=58.4714977372 b=-34.4067351939 AvgError=0.595943201544\n",
        "iter:4000 a=58.4521028139 b=-34.3742492822 AvgError=0.597301542868\n",
        "iter:4500 a=58.4323786881 b=-34.3414194201 AvgError=0.598679075007\n",
        "iter:5000 a=58.412482634 b=-34.3083391986 AvgError=0.600075986589\n",
        "iter:5500 a=58.3924412633 b=-34.2750235973 AvgError=0.601492547743\n",
        "iter:6000 a=58.3722584064 b=-34.2414738834 AvgError=0.602929034792\n",
        "iter:6500 a=58.3519339168 b=-34.2076889246 AvgError=0.604385728019\n",
        "iter:7000 a=58.3314669493 b=-34.1736671608 AvgError=0.605862911651\n",
        "iter:7500 a=58.310856531 b=-34.1394069477 AvgError=0.607360873915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iter:8000 a=58.2901016608 b=-34.1049066168 AvgError=0.608879907091\n",
        "iter:8500 a=58.2692013273 b=-34.0701644858 AvgError=0.61042030757\n",
        "iter:9000 a=58.248154511 b=-34.0351788599 AvgError=0.611982375914\n",
        "iter:9500 a=58.2269601854 b=-33.9999480327 AvgError=0.61356641691\n",
        "iter:10000 a=58.2056173165 b=-33.9644702856 AvgError=0.615172739634\n",
        "iter:10500 a=58.1841248633 b=-33.928743888 AvgError=0.616801657509\n",
        "iter:11000 a=58.1624817775 b=-33.8927670973 AvgError=0.618453488369\n",
        "iter:11500 a=58.1406870032 b=-33.8565381585 AvgError=0.620128554514\n",
        "iter:12000 a=58.1187394774 b=-33.8200553045 AvgError=0.621827182783\n",
        "iter:12500 a=58.0966381295 b=-33.7833167556 AvgError=0.623549704609\n",
        "iter:13000 a=58.0743818814 b=-33.7463207197 AvgError=0.625296456087\n",
        "iter:13500 a=58.0519696474 b=-33.7090653923 AvgError=0.627067778042\n",
        "iter:14000 a=58.0294003344 b=-33.671548956 AvgError=0.62886401609\n",
        "iter:14500 a=58.0066728413 b=-33.6337695808 AvgError=0.630685520713\n",
        "iter:15000 a=57.9837860597 b=-33.5957254239 AvgError=0.632532647318\n",
        "iter:15500 a=57.960738873 b=-33.5574146296 AvgError=0.634405756314"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iter:16000 a=57.9375301571 b=-33.518835329 AvgError=0.63630521318\n",
        "iter:16500 a=57.9141587798 b=-33.4799856403 AvgError=0.638231388534\n",
        "iter:17000 a=57.8906236012 b=-33.4408636685 AvgError=0.640184658211\n",
        "iter:17500 a=57.8669234732 b=-33.4014675052 AvgError=0.642165403327\n",
        "iter:18000 a=57.8430572398 b=-33.3617952287 AvgError=0.644174010365\n",
        "iter:18500 a=57.8190237367 b=-33.3218449038 AvgError=0.646210871239\n",
        "iter:19000 a=57.7948217916 b=-33.2816145819 AvgError=0.64827638338\n",
        "iter:19500 a=57.770450224 b=-33.2411023005 AvgError=0.650370949806\n",
        "iter:20000 a=57.7459078451 b=-33.2003060834 AvgError=0.652494979208\n",
        "iter:20500 a=57.7211934578 b=-33.1592239406 AvgError=0.654648886022\n",
        "iter:21000 a=57.6963058563 b=-33.1178538683 AvgError=0.656833090516\n",
        "iter:21500 a=57.6712438269 b=-33.0761938484 AvgError=0.659048018867\n",
        "iter:22000 a=57.6460061469 b=-33.0342418488 AvgError=0.661294103251\n",
        "iter:22500 a=57.6205915854 b=-32.991995823 AvgError=0.663571781919\n",
        "iter:23000 a=57.5949989025 b=-32.9494537105 AvgError=0.665881499289\n",
        "iter:23500 a=57.56922685 b=-32.906613436 AvgError=0.668223706029\n",
        "iter:24000 a=57.5432741707 b=-32.8634729097 AvgError=0.670598859148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iter:24500 a=57.5171395986 b=-32.8200300275 AvgError=0.673007422081\n",
        "iter:25000 a=57.4908218589 b=-32.7762826701 AvgError=0.675449864785\n",
        "iter:25500 a=57.4643196679 b=-32.7322287035 AvgError=0.677926663825\n",
        "iter:26000 a=57.4376317328 b=-32.687865979 AvgError=0.68043830247\n",
        "iter:26500 a=57.4107567517 b=-32.6431923325 AvgError=0.682985270788\n",
        "iter:27000 a=57.3836934139 b=-32.5982055849 AvgError=0.685568065739\n",
        "iter:27500 a=57.3564403991 b=-32.5529035417 AvgError=0.688187191274\n",
        "iter:28000 a=57.328996378 b=-32.5072839933 AvgError=0.690843158434\n",
        "iter:28500 a=57.3013600118 b=-32.4613447142 AvgError=0.693536485447\n",
        "iter:29000 a=57.2735299526 b=-32.4150834636 AvgError=0.696267697831\n",
        "iter:29500 a=57.2455048427 b=-32.368497985 AvgError=0.699037328496\n",
        "i0 x=1.47 y=52.21 yhat=51.7878095767"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "i1 x=1.5 y=53.12 yhat=53.5043297753\n",
        "i2 x=1.52 y=54.48 yhat=54.6486765744\n",
        "i3 x=1.55 y=55.84 yhat=56.3651967731\n",
        "i4 x=1.57 y=57.2 yhat=57.5095435722\n",
        "i5 x=1.6 y=58.57 yhat=59.2260637709\n",
        "i6 x=1.63 y=59.93 yhat=60.9425839695\n",
        "i7 x=1.65 y=61.29 yhat=62.0869307686\n",
        "i8 x=1.68 y=63.11 yhat=63.8034509673\n",
        "i9 x=1.7 y=64.47 yhat=64.9477977664\n",
        "i10 x=1.73 y=66.28 yhat=66.664317965\n",
        "i11 x=1.75 y=68.1 yhat=67.8086647641\n",
        "i12 x=1.78 y=69.92 yhat=69.5251849628\n",
        "i13 x=1.8 y=72.19 yhat=70.6695317619\n",
        "i14 x=1.83 y=74.46 yhat=72.3860519605\n",
        "y=57.2173399551x+-32.3216801573, error=0.701840261426\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiIiIiLB7P8BEvcNCDT/lx4AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x92a6450>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sympy as sp  # sympy \ub294 \ubcc0\uc218 \u3145\uc120\uc5b8\n",
      "\n",
      "from sympy import symbols\n",
      "from sympy import solve\n",
      "\n",
      "x,y=symbols('x y')\n",
      "f=x**2 + y**2\n",
      "gfx=sp.diff(f,x)\n",
      "gfy=sp.diff(f,y)\n",
      "print \"gradient=({0},{1})\".format(gfx,gfy)\n",
      "print solve([gfx,gfy],[x,y])  # 0\uc73c\ub85c solve \n",
      "\n",
      "print gfx.subs(x,1)\n",
      "print gfy.subs(y,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}